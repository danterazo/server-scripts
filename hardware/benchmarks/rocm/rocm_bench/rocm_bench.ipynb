{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671af6ad",
   "metadata": {},
   "source": [
    "# ROCm PyTorch Benchmark for 9070 XT\n",
    "**NOTE:** This didn't work in WSL2. It'd _probably_ work in a native Linux environment, though.\n",
    "\n",
    "## Environment & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c82a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ddd41f",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af8b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS: int = 8\n",
    "BATCH_SIZE: int = 512\n",
    "WIDTH: int = 224\n",
    "HEIGHT: int = 224\n",
    "CLASSES: int = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f1f4bb",
   "metadata": {},
   "source": [
    "## Define Training Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959f4141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc067c6",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ce1baae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/dante/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpytorch/vision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresnet50\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m      2\u001b[39m optimizer: AdamW = AdamW(params=model.parameters(), lr=\u001b[32m1e-3\u001b[39m)\n\u001b[32m      3\u001b[39m criterion: CrossEntropyLoss = CrossEntropyLoss()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scripts/hardware/benchmarks/rocm/.venv/lib/python3.12/site-packages/torch/hub.py:647\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source == \u001b[33m\"\u001b[39m\u001b[33mgithub\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    638\u001b[39m     repo_or_dir = _get_cache_or_reload(\n\u001b[32m    639\u001b[39m         repo_or_dir,\n\u001b[32m    640\u001b[39m         force_reload,\n\u001b[32m   (...)\u001b[39m\u001b[32m    644\u001b[39m         skip_validation=skip_validation,\n\u001b[32m    645\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m model = \u001b[43m_load_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scripts/hardware/benchmarks/rocm/.venv/lib/python3.12/site-packages/torch/hub.py:677\u001b[39m, in \u001b[36m_load_local\u001b[39m\u001b[34m(hubconf_dir, model, *args, **kwargs)\u001b[39m\n\u001b[32m    675\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _add_to_sys_path(hubconf_dir):\n\u001b[32m    676\u001b[39m     hubconf_path = os.path.join(hubconf_dir, MODULE_HUBCONF)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     hub_module = \u001b[43m_import_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODULE_HUBCONF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhubconf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    679\u001b[39m     entry = _load_entry_from_hubconf(hub_module, model)\n\u001b[32m    680\u001b[39m     model = entry(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scripts/hardware/benchmarks/rocm/.venv/lib/python3.12/site-packages/torch/hub.py:115\u001b[39m, in \u001b[36m_import_module\u001b[39m\u001b[34m(name, path)\u001b[39m\n\u001b[32m    113\u001b[39m module = importlib.util.module_from_spec(spec)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec.loader, Loader)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:999\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/torch/hub/pytorch_vision_main/hubconf.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Optional list of dependencies required by the package\u001b[39;00m\n\u001b[32m      2\u001b[39m dependencies = [\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_model_weights, get_weight\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malexnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alexnet\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconvnext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convnext_base, convnext_large, convnext_small, convnext_tiny\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/torch/hub/pytorch_vision_main/torchvision/__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/torch/hub/pytorch_vision_main/torchvision/_meta_registrations.py:25\u001b[39m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroi_align\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/torch/hub/pytorch_vision_main/torchvision/_meta_registrations.py:18\u001b[39m, in \u001b[36mregister_meta.<locals>.wrapper\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(fn):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextension\u001b[49m._has_ops():\n\u001b[32m     19\u001b[39m         get_meta_lib().impl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch.ops.torchvision, op_name), overload_name), fn)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(repo_or_dir=\"pytorch/vision\", model=\"resnet50\", weights=None).to(device)\n",
    "optimizer: AdamW = AdamW(params=model.parameters(), lr=1e-3)\n",
    "criterion: CrossEntropyLoss = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e99d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0db8d80b",
   "metadata": {},
   "source": [
    "## Start Training Loop(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1648853",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting synthetic training loop...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    inputs: Tensor = torch.randn(BATCH_SIZE, 3, HEIGHT, WIDTH, device=device)\n",
    "    targets: Tensor = torch.randint(0, CLASSES, (BATCH_SIZE,), device=device)\n",
    "\n",
    "    start: float = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    outputs: Tensor = model(inputs)\n",
    "    loss: Tensor = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    end: float = time.time()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{EPOCHS} done - Loss: {loss.item():.4f} - Time: {end - start:.2f}s\"\n",
    "    )\n",
    "\n",
    "print(\"GPU benchmark complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
